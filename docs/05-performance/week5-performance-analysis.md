# Week 5 성능 테스트 및 최적화 분석

## 개요

k6 부하 테스트 도구를 사용하여 시스템 성능을 측정하고 병목 지점을 분석한 후 최적화를 수행했습니다.

## 테스트 환경

- **도구**: k6 v1.3.0
- **테스트 시나리오**:
  - 30초: 1명 → 10명 동시 사용자로 증가
  - 1분: 10명 동시 사용자 유지
  - 30초: 10명 → 0명으로 감소
- **테스트 엔드포인트**:
  - Dashboard (/)
  - Blog (/blog/)
  - Blog API (/blog/api/posts)
  - Load Balancer Health (/lb-health)

## 초기 성능 측정 결과

### 성능 지표

| 지표 | 값 | 목표 | 달성 여부 |
|------|-----|------|-----------|
| P95 응답 시간 | 835.68ms | < 500ms | X |
| 평균 응답 시간 | 194.66ms | N/A | - |
| 최대 응답 시간 | 1.29s | N/A | - |
| HTTP 실패율 | 0.00% | < 1% | O |

### 엔드포인트별 성능

| 엔드포인트 | 목표 | 성공률 | 실패율 |
|-----------|------|--------|--------|
| Dashboard < 1s | < 1s | 95% (188/196) | 5% |
| Blog < 1s | < 1s | 96% (189/197) | 4% |
| Blog API < 500ms | < 500ms | 89% (175/196) | 11% |
| LB Health < 200ms | < 200ms | 77% (151/196) | 23% |

## 병목 지점 분석

### 1. Replica 수 부족

**문제**:
- 모든 주요 서비스가 replica 1개로 실행
- HPA의 minReplicas가 1로 설정되어 스케일업 발생 안 함
- CPU 사용률 3-5%로 매우 낮아 HPA threshold (70%) 도달 불가

**영향**:
- 단일 Pod가 모든 부하 처리
- 응답 시간 증가
- 장애 발생 시 서비스 중단 위험

### 2. Load Balancer Health 엔드포인트 병목

**문제**:
- 23% 요청이 200ms 목표 초과
- 가장 큰 성능 병목 지점

**원인 분석**:
- CPU/메모리 부족이 아님 (사용률 매우 낮음)
- 애플리케이션 로직 또는 네트워크 지연 문제
- Istio 프록시 오버헤드 가능성

## 최적화 작업

### 1. HPA minReplicas 조정

**변경 내용**:
```yaml
# Before
minReplicas: 1
maxReplicas: 5

# After
minReplicas: 2
maxReplicas: 5
```

**적용 대상**:
- prod-user-service-hpa
- prod-auth-service-hpa
- prod-blog-service-hpa
- prod-api-gateway-hpa

**목적**:
- 최소 2개 replica 유지로 고가용성 확보
- 부하 분산을 통한 응답 시간 개선
- 장애 복구 능력 향상

## 최적화 후 성능 측정 결과

### 성능 지표 비교

| 지표 | 최적화 전 | 최적화 후 | 개선율 |
|------|-----------|-----------|--------|
| P95 응답 시간 | 835.68ms | 738.75ms | **11.6% 감소** |
| 평균 응답 시간 | 194.66ms | 180.35ms | **7.4% 감소** |
| 최대 응답 시간 | 1.29s | 1.84s | -42.6% |

### 엔드포인트별 성능 비교

| 엔드포인트 | 최적화 전 | 최적화 후 | 개선 |
|-----------|-----------|-----------|------|
| Dashboard < 1s | 95% | 98% | +3% |
| Blog < 1s | 96% | 97% | +1% |
| Blog API < 500ms | 89% | 86% | -3% |
| LB Health < 200ms | 77% | 74% | -3% |

## 문제점 및 남은 과제

### 1. Threshold 미달성

**현재 상태**:
- P95 목표: 500ms
- P95 실제: 738.75ms
- **238.75ms 초과** (47.8% 초과)

### 2. 일부 엔드포인트 성능 악화

**Blog API와 LB Health**:
- 최적화 후 오히려 실패율 증가
- 원인: 테스트 변동성 또는 다른 병목 요인

### 3. 근본 원인 미해결

**분석 필요 사항**:
- 애플리케이션 코드의 sleep/delay 로직
- 데이터베이스 쿼리 성능
- Istio 프록시 오버헤드
- 네트워크 지연 (mTLS 암호화)

## 추가 최적화 권장 사항

### 단기 개선안

1. **애플리케이션 프로파일링**:
   - 각 서비스의 응답 시간 로깅
   - 느린 API 엔드포인트 식별
   - 데이터베이스 쿼리 최적화

2. **Istio 설정 최적화**:
   - 프록시 리소스 제한 증가
   - 연결 풀 설정 조정
   - Keep-Alive 활성화

3. **캐싱 전략**:
   - Redis 캐싱 활용
   - Blog API 응답 캐싱
   - Static content CDN 활용

### 장기 개선안

1. **데이터베이스 최적화**:
   - 인덱스 추가
   - 쿼리 최적화
   - Read Replica 추가

2. **아키텍처 개선**:
   - 마이크로서비스 간 통신 최적화
   - 비동기 처리 도입
   - 이벤트 기반 아키텍처 고려

3. **인프라 확장**:
   - Node 리소스 증가
   - Pod 리소스 제한 조정
   - HPA CPU threshold 하향 조정

## 결론

HPA minReplicas 조정을 통해 **11.6%의 P95 응답 시간 개선**을 달성했으나, 여전히 목표 threshold (P95 < 500ms)를 달성하지 못했습니다.

추가적인 성능 개선을 위해서는:
1. 애플리케이션 레벨의 최적화 필요
2. 데이터베이스 쿼리 성능 개선 필요
3. Istio 프록시 오버헤드 분석 및 최적화 필요

현재 시스템은 10명의 동시 사용자 부하에서 **0% HTTP 실패율**을 유지하며 안정적으로 작동하고 있으며, replica 증가를 통해 고가용성이 확보되었습니다.
